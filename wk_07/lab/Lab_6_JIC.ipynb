{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#d35400'> Lab 6 | Statistical Exploratory Data Analysis </font>\n",
    "Welcome to Lab 6! The goal in lab 6 is to use hypothesis testing to conduct a exploratory data analysis. To achieve this, we consider life expectancy, but this time we work with a new data set of US county level information. The goal will be to work with a response variable and explore which variables might make good predictors for this response.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"tennis_dog.jpg\" alt=\"Alt Text\", width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> About the Dataset </font>\n",
    "We start off the Jupyter Notebook by exploring the dataset. Since it is in a `.json` format, we convert it into a `pandas` data frame, and then perform the necessary statistical calculations, such as using `.info()` and `.describe()`. To achieve this, we make sure we do all the necessary imports that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fips</th>\n",
       "      <th>state</th>\n",
       "      <th>land_area (km^2)</th>\n",
       "      <th>area (km^2)</th>\n",
       "      <th>longitude (deg)</th>\n",
       "      <th>latitude (deg)</th>\n",
       "      <th>noaa</th>\n",
       "      <th>zip-codes</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>covid-deaths</th>\n",
       "      <th>covid-confirmed</th>\n",
       "      <th>covid-vaccination</th>\n",
       "      <th>elections</th>\n",
       "      <th>edu</th>\n",
       "      <th>poverty-rate</th>\n",
       "      <th>cost-of-living</th>\n",
       "      <th>industry</th>\n",
       "      <th>health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuming county</td>\n",
       "      <td>31039</td>\n",
       "      <td>NE</td>\n",
       "      <td>1477.641638</td>\n",
       "      <td>1488.343176</td>\n",
       "      <td>-96.787366</td>\n",
       "      <td>41.916346</td>\n",
       "      <td>{'prcp': 30.5, 'snow': 28.2, 'temp': 48.8, 'al...</td>\n",
       "      <td>[68047, 68641, 68004, 68045, 68788, 68716, 687...</td>\n",
       "      <td>{'non_hispanic_white_alone_male': 0.4379380510...</td>\n",
       "      <td>...</td>\n",
       "      <td>58610</td>\n",
       "      <td>{'2020-02-01': 0, '2020-03-01': 0, '2020-04-01...</td>\n",
       "      <td>{'2020-02-01': 0, '2020-03-01': 0, '2020-04-01...</td>\n",
       "      <td>{'2021-01-01': 0.0, '2021-02-01': 61.4, '2021-...</td>\n",
       "      <td>{'2008': {'total': 4087, 'dem': 1274, 'gop': 2...</td>\n",
       "      <td>{'less-than-high-school': 11.6, 'high-school':...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>{'living_wage': 12.89, 'food_costs': 3246.0, '...</td>\n",
       "      <td>{'Construction': {'payroll': 8307000, 'employe...</td>\n",
       "      <td>{'% Fair or Poor Health': 14.590580443, 'Avera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   fips state  land_area (km^2)  area (km^2)  longitude (deg)  \\\n",
       "0  cuming county  31039    NE       1477.641638  1488.343176       -96.787366   \n",
       "\n",
       "   latitude (deg)                                               noaa  \\\n",
       "0       41.916346  {'prcp': 30.5, 'snow': 28.2, 'temp': 48.8, 'al...   \n",
       "\n",
       "                                           zip-codes  \\\n",
       "0  [68047, 68641, 68004, 68045, 68788, 68716, 687...   \n",
       "\n",
       "                                                race  ... avg_income  \\\n",
       "0  {'non_hispanic_white_alone_male': 0.4379380510...  ...      58610   \n",
       "\n",
       "                                        covid-deaths  \\\n",
       "0  {'2020-02-01': 0, '2020-03-01': 0, '2020-04-01...   \n",
       "\n",
       "                                     covid-confirmed  \\\n",
       "0  {'2020-02-01': 0, '2020-03-01': 0, '2020-04-01...   \n",
       "\n",
       "                                   covid-vaccination  \\\n",
       "0  {'2021-01-01': 0.0, '2021-02-01': 61.4, '2021-...   \n",
       "\n",
       "                                           elections  \\\n",
       "0  {'2008': {'total': 4087, 'dem': 1274, 'gop': 2...   \n",
       "\n",
       "                                                 edu  poverty-rate  \\\n",
       "0  {'less-than-high-school': 11.6, 'high-school':...           8.9   \n",
       "\n",
       "                                      cost-of-living  \\\n",
       "0  {'living_wage': 12.89, 'food_costs': 3246.0, '...   \n",
       "\n",
       "                                            industry  \\\n",
       "0  {'Construction': {'payroll': 8307000, 'employe...   \n",
       "\n",
       "                                              health  \n",
       "0  {'% Fair or Poor Health': 14.590580443, 'Avera...  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# converting the .json file into a pandas data frame\n",
    "county_df = pd.read_json(\"counties.json\")\n",
    "\n",
    "# displaying the counties data frame of the first row\n",
    "county_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3142 entries, 0 to 3141\n",
      "Data columns (total 29 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   name                    3142 non-null   object \n",
      " 1   fips                    3142 non-null   int64  \n",
      " 2   state                   3142 non-null   object \n",
      " 3   land_area (km^2)        3142 non-null   float64\n",
      " 4   area (km^2)             3142 non-null   float64\n",
      " 5   longitude (deg)         3142 non-null   float64\n",
      " 6   latitude (deg)          3142 non-null   float64\n",
      " 7   noaa                    3142 non-null   object \n",
      " 8   zip-codes               3142 non-null   object \n",
      " 9   race                    3142 non-null   object \n",
      " 10  age                     3142 non-null   object \n",
      " 11  male                    3142 non-null   int64  \n",
      " 12  female                  3142 non-null   int64  \n",
      " 13  population              3142 non-null   object \n",
      " 14  deaths                  3142 non-null   object \n",
      " 15  bls                     3136 non-null   object \n",
      " 16  life-expectancy         3142 non-null   float64\n",
      " 17  fatal_police_shootings  3142 non-null   object \n",
      " 18  police_deaths           3142 non-null   int64  \n",
      " 19  avg_income              3142 non-null   int64  \n",
      " 20  covid-deaths            3142 non-null   object \n",
      " 21  covid-confirmed         3142 non-null   object \n",
      " 22  covid-vaccination       3142 non-null   object \n",
      " 23  elections               3112 non-null   object \n",
      " 24  edu                     3142 non-null   object \n",
      " 25  poverty-rate            3141 non-null   float64\n",
      " 26  cost-of-living          3142 non-null   object \n",
      " 27  industry                3134 non-null   object \n",
      " 28  health                  3141 non-null   object \n",
      "dtypes: float64(6), int64(5), object(18)\n",
      "memory usage: 712.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Summary Statistics: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Description of Dataset: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>land_area (km^2)</th>\n",
       "      <th>area (km^2)</th>\n",
       "      <th>longitude (deg)</th>\n",
       "      <th>latitude (deg)</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>life-expectancy</th>\n",
       "      <th>police_deaths</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>poverty-rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3.142000e+03</td>\n",
       "      <td>3.142000e+03</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3142.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30383.652769</td>\n",
       "      <td>2911.729752</td>\n",
       "      <td>3140.236735</td>\n",
       "      <td>-92.293441</td>\n",
       "      <td>38.455993</td>\n",
       "      <td>5.145045e+04</td>\n",
       "      <td>5.301789e+04</td>\n",
       "      <td>77.750662</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>44188.344685</td>\n",
       "      <td>14.455333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15162.512005</td>\n",
       "      <td>9360.572636</td>\n",
       "      <td>9960.549977</td>\n",
       "      <td>12.975221</td>\n",
       "      <td>5.304694</td>\n",
       "      <td>1.638677e+05</td>\n",
       "      <td>1.696276e+05</td>\n",
       "      <td>2.382180</td>\n",
       "      <td>0.139440</td>\n",
       "      <td>12761.680107</td>\n",
       "      <td>5.799981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>5.300264</td>\n",
       "      <td>5.300296</td>\n",
       "      <td>-175.687790</td>\n",
       "      <td>19.593667</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>66.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18541.000000</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18177.500000</td>\n",
       "      <td>1115.844505</td>\n",
       "      <td>1154.514541</td>\n",
       "      <td>-98.233756</td>\n",
       "      <td>34.696344</td>\n",
       "      <td>5.459750e+03</td>\n",
       "      <td>5.407250e+03</td>\n",
       "      <td>76.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36584.250000</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29176.000000</td>\n",
       "      <td>1595.516194</td>\n",
       "      <td>1687.209285</td>\n",
       "      <td>-90.394740</td>\n",
       "      <td>38.380621</td>\n",
       "      <td>1.286900e+04</td>\n",
       "      <td>1.282850e+04</td>\n",
       "      <td>77.935000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41974.000000</td>\n",
       "      <td>13.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45080.500000</td>\n",
       "      <td>2393.159486</td>\n",
       "      <td>2552.865615</td>\n",
       "      <td>-83.430980</td>\n",
       "      <td>41.819157</td>\n",
       "      <td>3.415225e+04</td>\n",
       "      <td>3.451250e+04</td>\n",
       "      <td>79.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48821.500000</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56045.000000</td>\n",
       "      <td>377030.936019</td>\n",
       "      <td>382984.116616</td>\n",
       "      <td>-67.608136</td>\n",
       "      <td>69.377717</td>\n",
       "      <td>4.949041e+06</td>\n",
       "      <td>5.090066e+06</td>\n",
       "      <td>86.830000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>251728.000000</td>\n",
       "      <td>47.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fips  land_area (km^2)    area (km^2)  longitude (deg)  \\\n",
       "count   3142.000000       3142.000000    3142.000000      3142.000000   \n",
       "mean   30383.652769       2911.729752    3140.236735       -92.293441   \n",
       "std    15162.512005       9360.572636    9960.549977        12.975221   \n",
       "min     1001.000000          5.300264       5.300296      -175.687790   \n",
       "25%    18177.500000       1115.844505    1154.514541       -98.233756   \n",
       "50%    29176.000000       1595.516194    1687.209285       -90.394740   \n",
       "75%    45080.500000       2393.159486    2552.865615       -83.430980   \n",
       "max    56045.000000     377030.936019  382984.116616       -67.608136   \n",
       "\n",
       "       latitude (deg)          male        female  life-expectancy  \\\n",
       "count     3142.000000  3.142000e+03  3.142000e+03      3142.000000   \n",
       "mean        38.455993  5.145045e+04  5.301789e+04        77.750662   \n",
       "std          5.304694  1.638677e+05  1.696276e+05         2.382180   \n",
       "min         19.593667  4.100000e+01  4.500000e+01        66.810000   \n",
       "25%         34.696344  5.459750e+03  5.407250e+03        76.100000   \n",
       "50%         38.380621  1.286900e+04  1.282850e+04        77.935000   \n",
       "75%         41.819157  3.415225e+04  3.451250e+04        79.490000   \n",
       "max         69.377717  4.949041e+06  5.090066e+06        86.830000   \n",
       "\n",
       "       police_deaths     avg_income  poverty-rate  \n",
       "count    3142.000000    3142.000000   3141.000000  \n",
       "mean        0.017187   44188.344685     14.455333  \n",
       "std         0.139440   12761.680107      5.799981  \n",
       "min         0.000000   18541.000000      2.700000  \n",
       "25%         0.000000   36584.250000     10.400000  \n",
       "50%         0.000000   41974.000000     13.400000  \n",
       "75%         0.000000   48821.500000     17.500000  \n",
       "max         3.000000  251728.000000     47.700000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the ipython library\n",
    "from IPython.display import display\n",
    "\n",
    "# displaying the descriptive statistics of the data frame\n",
    "display(\"Summary Statistics: \", county_df.info())\n",
    "\n",
    "# displaying the summary of the dataset\n",
    "display(\"Description of Dataset: \", county_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to `.info()`, we can see that some of the data types that the columns have are `int64`, `float64` and `object`. According to `.describe()`, we can see the following count, mean, standard deviation and more in the table above this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> JSON to Excel & CSV </font>\n",
    "We would like to convert the .json file into a excel and .csv file, and then download these files directly into the directory. This will allow us to examine the dataset better, seeing what columns exist as well as other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the .json to a .csv file\n",
    "county_df.to_csv(\"counties.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# converting the .json to a excel file\n",
    "county_df.to_excel(\"counties.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 1 </font> | Data Preparation\n",
    "In this section, we load the `counties.csv` file into a Pandas data frame using `pd.read_csv()`. We perform basic feature engineering by creating new columns for COVID-19 deaths and confirmed cases per capita, an indicator for above-average life expectancy, the largest industry by employees and the most common educational level in each country. To achieve this, we perform the following steps:\n",
    "- [x] Divide the number of covid deaths in each county in 2022-03-01 by the 2019 population – add a column called covid-deaths total per capita containing this data to the dataframe. \n",
    "- [x] Divide the number of covid confirmed cases in each county in 2022-03-01 by the 2019 population – add a column called covid-confirmed total per capita containing this data to the dataframe.\n",
    "- [x] Create an indicator that measures whether a county has greater-than-average life expectancy. Add a column called above average life-expectancy containing this data to the dataframe.\n",
    "- [x] Record for each county the largest industry by number of employees. You will need to use the 20 variables in the data named industry/.../employees. To do this, you will need to ﬁll missing values in these variables. For simplicity, ﬁll missing values with 0 (you may ﬁnd .ﬁllna useful). Put this information into a single column called biggest industry.\n",
    "- [x] Record for each county the modal educational level. You will need to use the 4 variables in the data named edu/.... Put this information into a single column called county_modal_ed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> COVID Deaths </font>\n",
    "We start this section off by dividing the number of covid deaths in each country in March 1, 2022 by the 2019 population. We then add a column called `covid-deaths_total_per_capita` that contains this data to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using json_normalize to normalize semi-structured data into a flat table\n",
    "death_df = pd.json_normalize(county_df[\"covid-deaths\"])\n",
    "population_df = pd.json_normalize(county_df[\"population\"])\n",
    "\n",
    "# extracting relevant data from both columns\n",
    "death_df.columns = death_df.columns.map(lambda x: x.split(\".\")[-1])\n",
    "population_df.columns = population_df.columns.map(lambda x: x.split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Death Observations:  3142\n",
      "Number of 2019 Observations:  3142\n"
     ]
    }
   ],
   "source": [
    "# checking length of the 2022-03-01 column\n",
    "death_length = len(death_df['2022-03-01'])\n",
    "print(\"Number of Death Observations: \", death_length)\n",
    "\n",
    "# checking length of the 2019 column\n",
    "year_length = len(population_df['2019'])\n",
    "print(\"Number of 2019 Observations: \", year_length)\n",
    "\n",
    "# converting the columns into a list\n",
    "death_list = death_df['2022-03-01'].tolist()\n",
    "population_list = population_df['2019'].tolist()\n",
    "\n",
    "# dividing covid deaths by the 2019 population\n",
    "death_by_year_list = [death / year for death, year in zip(death_list, population_list)]\n",
    "\n",
    "# adding the list as a column to a data frame\n",
    "county_df['covid-deaths_total_per_capita'] = death_by_year_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> COVID Confirms </font>\n",
    "Next, we move on to dividing the number of covid confirmed cases in each county in 2022-03-01 by the 2019 population. We add a column called `above_average_life_expectancy` containing this data to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Covid Confirmed Observations:  3142\n"
     ]
    }
   ],
   "source": [
    "# using json_normalize to normalize semi-structured data into a flat table\n",
    "confirm_df = pd.json_normalize(county_df['covid-confirmed'])\n",
    "\n",
    "# converting the data frame column into a list\n",
    "confirm_list = confirm_df['2022-03-01'].tolist()\n",
    "\n",
    "# checking the length of the confirm list\n",
    "print(\"Number of Covid Confirmed Observations: \", len(confirm_list))\n",
    "\n",
    "# dividing covid confirms by the 2019 population\n",
    "confirm_by_year_list = [confirm / year for confirm, year in zip(confirm_list, population_list)]\n",
    "\n",
    "# adding the list as a column to a data frame\n",
    "county_df['covid-confirmed_total_per_capita'] = confirm_by_year_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Life Expectancy Indicator </font>\n",
    "Next, we move on creating a indicator, with regards to whether a county has a greater than average life expectancy. We then add a column called `above_average_life-expectancy` to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Life Expectancy:  77.75066199872693\n",
      "Length of Life Expectancy List:  3142\n",
      "Length of Evaluation List:  3142\n"
     ]
    }
   ],
   "source": [
    "# importing the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# calculating the average of the life expectancy feature\n",
    "average_life_expectancy = np.mean(county_df['life-expectancy'])\n",
    "print(\"Average Life Expectancy: \", average_life_expectancy)\n",
    "print(\"Length of Life Expectancy List: \", len(county_df['life-expectancy']))\n",
    "\n",
    "# converting into a list\n",
    "life_expectancy_list = county_df['life-expectancy']\n",
    "\n",
    "# evaluating if a county has a above average life expectancy or not\n",
    "evaluation_list = []\n",
    "for index in range(0, len(life_expectancy_list)):\n",
    "    if(life_expectancy_list[index] > average_life_expectancy):\n",
    "        evaluation_list.append(True)\n",
    "    else:\n",
    "        evaluation_list.append(False)\n",
    "\n",
    "# checking the length of the evaluation list \n",
    "print(\"Length of Evaluation List: \", len(evaluation_list))\n",
    "\n",
    "# appending the evaluation list as a column\n",
    "county_df['above_average_life-expectancy'] = evaluation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Largest Industry </font>\n",
    "Next, we move on recording for each country the largest industry by the number of employees. Once we find the industry, we put this information into a single column called `biggest_industry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Insutry Names:  3142\n"
     ]
    }
   ],
   "source": [
    "# using json_normalize to normalize semi-structured data into a flat table\n",
    "industry_df = pd.json_normalize(county_df['industry'])\n",
    "\n",
    "# filling in the missing values in the data frame using just 0\n",
    "industry_df.fillna(0, inplace=True)\n",
    "\n",
    "# dropping all the columns ending with .payroll\n",
    "for column in industry_df.columns:\n",
    "    if column.endswith('.payroll'):\n",
    "        industry_df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "# setting up a list of industries with higheest number of employees\n",
    "high_employment_industry = []\n",
    "\n",
    "# finding the indsutry with the highest number of employees\n",
    "for index in range(0, len(industry_df)):\n",
    "    row = industry_df.iloc[index]\n",
    "    column_name = row.idxmax()\n",
    "    high_employment_industry.append(column_name)\n",
    "\n",
    "# setting up a list of industry names\n",
    "industry_list = []\n",
    "\n",
    "# performing string slicing to get just the industry\n",
    "for industry in high_employment_industry:\n",
    "    dot_position = industry.rfind('.')\n",
    "    industry_name = industry[:dot_position]\n",
    "    industry_list.append(industry_name)\n",
    "\n",
    "# checking the length of the industry list\n",
    "print(\"Length of Insutry Names: \", len(industry_list))\n",
    "\n",
    "# adding the names of the indsutries to the data frame\n",
    "county_df['biggest_industry'] = industry_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Education Level </font>\n",
    "Next, we record for each county the modal educational level. We need to use the 4 variables in the data. We then put this information into a single column called `county_modal_ed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Education Levels:  3142\n"
     ]
    }
   ],
   "source": [
    "# using json_normalize to normalize semi-structured data into a flat table\n",
    "education_df = pd.json_normalize(county_df['edu'])\n",
    "\n",
    "# setting up a list of education levels\n",
    "education_level_list = []\n",
    "\n",
    "# finding the modal education level using a for loop\n",
    "for index in range(0, len(education_df)):\n",
    "    row = education_df.iloc[index]\n",
    "    column_name = row.idxmax()\n",
    "    education_level_list.append(column_name)\n",
    "\n",
    "# checking the length of the education levels\n",
    "print(\"Length of Education Levels: \", len(education_level_list))\n",
    "\n",
    "# adding the education levels to the data frame\n",
    "county_df['county_modal_ed'] = education_level_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Checking for Presence of Columns </font>\n",
    "Lastly, we would like to check for the presence of the columns we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Columns Exist!\n"
     ]
    }
   ],
   "source": [
    "# checking for the presence of the columns we created\n",
    "column_list = ['covid-deaths_total_per_capita', 'covid-confirmed_total_per_capita', 'above_average_life-expectancy', 'biggest_industry', \n",
    "               'county_modal_ed']\n",
    "result = all(column in county_df.columns for column in column_list)\n",
    "\n",
    "# printing out the results\n",
    "if result:\n",
    "    print(\"All Columns Exist!\")\n",
    "else:\n",
    "    print(\"The Columns Don't Exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section One </font>\n",
    "- https://stackoverflow.com/questions/34341974/nested-json-to-pandas-dataframe-with-specific-format\n",
    "- https://stackoverflow.com/questions/12604909/pandas-how-to-change-all-the-values-of-a-column\n",
    "- https://stackoverflow.com/questions/78157298/load-convert-json-to-excel-with-pandas-in-python\n",
    "- https://stackoverflow.com/questions/24870306/how-to-check-if-a-column-exists-in-pandas\n",
    "- https://www.reddit.com/r/learnpython/comments/q5e07m/pandas_fillna_replacing_every_value_with_nan/\n",
    "- https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-a-pandas-dataframe\n",
    "- https://stackoverflow.com/questions/13411544/delete-a-column-from-a-pandas-dataframe\n",
    "- https://stackoverflow.com/questions/10202570/find-row-where-values-for-column-is-maximal-in-a-pandas-dataframe\n",
    "- https://www.geeksforgeeks.org/python-find-position-of-a-character-in-given-string/\n",
    "- https://www.geeksforgeeks.org/string-slicing-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 2 </font> | Life Expectancy\n",
    "In this section, we will analyze the relationship between life expectancy and various numerical predictors using Pearson's correlation and tested categorical associations with the Kruskal-Wallis test. The results would indicate which variables have statistically significant relationships with life expectancy $\\alpha$ = 0.05, which provides insight into key factors including county-level differences. We achieve this in the following steps:\n",
    "- [x] In this section we are going to explore which variables are predictive of US county level life expectancy. Thus we will be using life-expectancy as our dependent variable, and we focus on other variables as potential predictors\n",
    "- [x] For each numerical potential predictor variable, use scipy.stats.linregress() to estimate the Pearson’s correlation coefficient and the statistical significance (p-value) of the correlation against the life-expectancy variable\n",
    "- [x] We can test for association between categorical and numerical variables using a Kruskal-Wallis test via the scipy.kruskal() function\n",
    "- [x] In a single table, indicate the variable name, test statistic, p-value, and whether there is a statistically significant relationship between that variable and life-expectancy at a threshold of α = 0.05, using all the hypothesis tests conducted in 2.2 and 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Linear Regression </font>\n",
    "For each numerical predictor, we use `scipy.stats.linregress()` to estimate the Pearson's correlation coefficient and the statistical signfigiance of the correlation against the life-expectancy variable. We then take those results to build a single table that indicates the variable name, test statistic and life-expectancy at a threshold of $/alpha$ = 0.05 using the hypothesis tests conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using json_normalize to normalize semi-structured data into a flat table\n",
    "noaa_df = pd.json_normalize(county_df['noaa'])\n",
    "deaths_df = pd.json_normalize(county_df['deaths'])\n",
    "bls_df = pd.json_normalize(county_df['bls'])\n",
    "vaccination_df = pd.json_normalize(county_df['covid-vaccination'])\n",
    "cost_of_living_df = pd.json_normalize(county_df['cost-of-living'])\n",
    "health_df = pd.json_normalize(county_df['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the statistics library from scipy\n",
    "import scipy.stats\n",
    "\n",
    "# building a function that returns the name, test statistic and p-value\n",
    "def linear_regression_function(feature_one, feature_two):\n",
    "\n",
    "    if feature_two.isnull().any():\n",
    "        null_rows = feature_two[feature_two.isnull()].index.tolist()\n",
    "        feature_one = feature_one.drop(null_rows)\n",
    "        feature_two = feature_two.drop(null_rows)\n",
    "\n",
    "    # calculating the linear regression\n",
    "    linear_regression = scipy.stats.linregress(feature_one, feature_two)\n",
    "\n",
    "    # calculating the test statisic, p-value and r-value\n",
    "    t_value = linear_regression.slope / linear_regression.stderr\n",
    "    p_value = linear_regression.pvalue\n",
    "    r_value = linear_regression.rvalue\n",
    "    statistical_signifigance = False\n",
    "\n",
    "    # whether statistically significant or not\n",
    "    if p_value < 0.05:\n",
    "        statistical_signifigance = True\n",
    "    \n",
    "    # return everything\n",
    "    return t_value, p_value, r_value, statistical_signifigance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the necessary data we need to pass in to our function\n",
    "dataframe_features = [\n",
    "    county_df['longitude (deg)'],\n",
    "    county_df['latitude (deg)'],\n",
    "    noaa_df['temp'],\n",
    "    noaa_df['altitude'],\n",
    "    county_df['male'],\n",
    "    deaths_df['suicides'],\n",
    "    deaths_df['homicides'],\n",
    "    bls_df['2020.unemployed'],\n",
    "    county_df['avg_income'],\n",
    "    county_df['covid-deaths_total_per_capita'],\n",
    "    county_df['covid-confirmed_total_per_capita'],\n",
    "    vaccination_df['2021-12-01'],\n",
    "    county_df['poverty-rate'],\n",
    "    cost_of_living_df['living_wage'],\n",
    "    cost_of_living_df['food_costs'],\n",
    "    cost_of_living_df['medical_costs'],\n",
    "    cost_of_living_df['housing_costs'],\n",
    "    cost_of_living_df['tax_costs'],\n",
    "    health_df['Average Number of Mentally Unhealthy Days'],\n",
    "    health_df['% Smokers'],\n",
    "    health_df['% Adults with Obesity'],\n",
    "    health_df['% Physically Inactive'],\n",
    "    health_df['% Long Commute - Drives Alone'],\n",
    "]\n",
    "\n",
    "# creating a list of all the variables for the table\n",
    "variable_names = [\n",
    "    'longitude (deg)', \n",
    "    'latitude (deg)', \n",
    "    'temp', \n",
    "    'altitude', \n",
    "    'male', \n",
    "    'suicides', \n",
    "    'homicides',\n",
    "    '2020.unemployed', \n",
    "    'avg_income', \n",
    "    'covid-deaths_total_per_capita', \n",
    "    'covid-confirmed_total_per_capita', \n",
    "    'vaccination.2021-12-01', ''\n",
    "    'poverty-rate', \n",
    "    'living_wage', \n",
    "    'food_costs', \n",
    "    'medical_costs', \n",
    "    'housing_costs',\n",
    "    'tax_costs', \n",
    "    'Average Number of Mentally Unhealthy Days', \n",
    "    '% Smokers',\n",
    "    '% Adults with Obesity',\n",
    "    '% Physically Inactive', \n",
    "    '% Long Commute - Drives Alone',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a number of lists\n",
    "t_values_list = []\n",
    "p_values_list = []\n",
    "r_values_list = []\n",
    "signifigance_list = []\n",
    "\n",
    "# running the function in a for loop and storing the results\n",
    "for feature in dataframe_features:\n",
    "    \n",
    "    # retrieving all the necessary daya\n",
    "    t_value, p_value, r_value, statistical_signifigance = linear_regression_function(county_df['life-expectancy'], feature)\n",
    "    \n",
    "    # appending to the instantiated lists\n",
    "    t_values_list.append(t_value)\n",
    "    p_values_list.append(p_value)\n",
    "    r_values_list.append(r_value)\n",
    "    signifigance_list.append(statistical_signifigance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Test Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Statistically Significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>longitude (deg)</td>\n",
       "      <td>-10.549703</td>\n",
       "      <td>1.358906e-25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latitude (deg)</td>\n",
       "      <td>27.255320</td>\n",
       "      <td>5.304361e-147</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temp</td>\n",
       "      <td>-30.046768</td>\n",
       "      <td>1.463919e-174</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altitude</td>\n",
       "      <td>15.650003</td>\n",
       "      <td>3.235692e-53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>9.709380</td>\n",
       "      <td>5.584895e-22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>suicides</td>\n",
       "      <td>9.414545</td>\n",
       "      <td>9.216754e-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>homicides</td>\n",
       "      <td>4.143451</td>\n",
       "      <td>3.552415e-05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020.unemployed</td>\n",
       "      <td>8.069614</td>\n",
       "      <td>9.946132e-16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avg_income</td>\n",
       "      <td>38.298671</td>\n",
       "      <td>1.111643e-263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covid-deaths_total_per_capita</td>\n",
       "      <td>-31.072288</td>\n",
       "      <td>4.616175e-185</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>covid-confirmed_total_per_capita</td>\n",
       "      <td>-15.200018</td>\n",
       "      <td>2.107299e-50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vaccination.2021-12-01</td>\n",
       "      <td>8.176386</td>\n",
       "      <td>4.197836e-16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poverty-rate</td>\n",
       "      <td>-54.793435</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>living_wage</td>\n",
       "      <td>21.421593</td>\n",
       "      <td>3.941282e-95</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>food_costs</td>\n",
       "      <td>22.636483</td>\n",
       "      <td>3.226331e-105</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>medical_costs</td>\n",
       "      <td>-9.044944</td>\n",
       "      <td>2.560844e-19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>housing_costs</td>\n",
       "      <td>20.814251</td>\n",
       "      <td>3.046873e-90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tax_costs</td>\n",
       "      <td>12.428512</td>\n",
       "      <td>1.179789e-34</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Average Number of Mentally Unhealthy Days</td>\n",
       "      <td>-65.001113</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>% Smokers</td>\n",
       "      <td>-61.225718</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>% Adults with Obesity</td>\n",
       "      <td>-30.831628</td>\n",
       "      <td>1.420991e-182</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>% Physically Inactive</td>\n",
       "      <td>-44.704013</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>% Long Commute - Drives Alone</td>\n",
       "      <td>-8.420080</td>\n",
       "      <td>5.643566e-17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Variable Name  Test Statistic        P-Value  \\\n",
       "0                             longitude (deg)      -10.549703   1.358906e-25   \n",
       "1                              latitude (deg)       27.255320  5.304361e-147   \n",
       "2                                        temp      -30.046768  1.463919e-174   \n",
       "3                                    altitude       15.650003   3.235692e-53   \n",
       "4                                        male        9.709380   5.584895e-22   \n",
       "5                                    suicides        9.414545   9.216754e-21   \n",
       "6                                   homicides        4.143451   3.552415e-05   \n",
       "7                             2020.unemployed        8.069614   9.946132e-16   \n",
       "8                                  avg_income       38.298671  1.111643e-263   \n",
       "9               covid-deaths_total_per_capita      -31.072288  4.616175e-185   \n",
       "10           covid-confirmed_total_per_capita      -15.200018   2.107299e-50   \n",
       "11                     vaccination.2021-12-01        8.176386   4.197836e-16   \n",
       "12                               poverty-rate      -54.793435   0.000000e+00   \n",
       "13                                living_wage       21.421593   3.941282e-95   \n",
       "14                                 food_costs       22.636483  3.226331e-105   \n",
       "15                              medical_costs       -9.044944   2.560844e-19   \n",
       "16                              housing_costs       20.814251   3.046873e-90   \n",
       "17                                  tax_costs       12.428512   1.179789e-34   \n",
       "18  Average Number of Mentally Unhealthy Days      -65.001113   0.000000e+00   \n",
       "19                                  % Smokers      -61.225718   0.000000e+00   \n",
       "20                      % Adults with Obesity      -30.831628  1.420991e-182   \n",
       "21                      % Physically Inactive      -44.704013   0.000000e+00   \n",
       "22              % Long Commute - Drives Alone       -8.420080   5.643566e-17   \n",
       "\n",
       "    Statistically Significant  \n",
       "0                        True  \n",
       "1                        True  \n",
       "2                        True  \n",
       "3                        True  \n",
       "4                        True  \n",
       "5                        True  \n",
       "6                        True  \n",
       "7                        True  \n",
       "8                        True  \n",
       "9                        True  \n",
       "10                       True  \n",
       "11                       True  \n",
       "12                       True  \n",
       "13                       True  \n",
       "14                       True  \n",
       "15                       True  \n",
       "16                       True  \n",
       "17                       True  \n",
       "18                       True  \n",
       "19                       True  \n",
       "20                       True  \n",
       "21                       True  \n",
       "22                       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a dicationary \n",
    "data_numerical = {\n",
    "    'Variable Name': variable_names,\n",
    "    'Test Statistic': t_values_list,\n",
    "    'P-Value': p_values_list,\n",
    "    \"Statistically Significant\": signifigance_list\n",
    "}\n",
    "\n",
    "# converting dicationary to data frame\n",
    "numerical_df = pd.DataFrame(data_numerical)\n",
    "\n",
    "# displaying the data frame as a table\n",
    "display(numerical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Association Test </font>\n",
    "Lastly, we would like to test for association between categorical and numerical variables using a Kruska-Wallis test. The numerical variable we use here is the `life-expectancy` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the kruskal function\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# creating a list of categorical features\n",
    "categorical_features = [\n",
    "    county_df['state'],\n",
    "    county_df['county_modal_ed'],\n",
    "    county_df['biggest_industry']\n",
    "]\n",
    "\n",
    "# creating a list of variable names for the table\n",
    "categorical_names = [\n",
    "    'state',\n",
    "    'county_modal_ed',\n",
    "    'biggest_indsutry'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that performs kruskal-wallis\n",
    "def kruskal_wallis(feature_one, feature_two):\n",
    "\n",
    "    # creating a list\n",
    "    samples_by_group = []\n",
    "\n",
    "    # setting up the for loop\n",
    "    for value in set(feature_one):\n",
    "        mask = feature_one == value\n",
    "        samples_by_group.append(feature_two[mask])\n",
    "    \n",
    "    # getting the statistics and probability\n",
    "    statistic, probability = kruskal(*samples_by_group)\n",
    "\n",
    "    # instatiating the statistical signfigance variable\n",
    "    statistical_signifigance = True\n",
    "\n",
    "    # whether statistically significant or not\n",
    "    if probability < 0.05:\n",
    "        statistical_signifigance = True\n",
    "\n",
    "    # returning the statistics and probability\n",
    "    return statistic, probability, statistical_signifigance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiating the lists to append to\n",
    "statistic_list = []\n",
    "probability_list = []\n",
    "hypothesis_list = []\n",
    "\n",
    "# setting up a for loop to retrieve the necessary values\n",
    "for category in categorical_features:\n",
    "    statistic, probability, statistical_signifigance = kruskal_wallis(category, county_df['life-expectancy'])\n",
    "    statistic_list.append(statistic)\n",
    "    probability_list.append(probability)\n",
    "    hypothesis_list.append(statistical_signifigance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m data_categorical \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable Name\u001b[39m\u001b[38;5;124m'\u001b[39m: categorical_names,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Statistic\u001b[39m\u001b[38;5;124m'\u001b[39m: statistic_list,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP-Value\u001b[39m\u001b[38;5;124m'\u001b[39m: probability_list,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatistically Significant\u001b[39m\u001b[38;5;124m\"\u001b[39m: hypothesis_list\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# converting dicationary to data frame\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m categorical_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# displaying the data frame as a table\u001b[39;00m\n\u001b[0;32m     13\u001b[0m display(categorical_df)\n",
      "File \u001b[1;32mc:\\Users\\chowdhuryj\\AppData\\Local\\anaconda3\\envs\\dataScienceEnv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\chowdhuryj\\AppData\\Local\\anaconda3\\envs\\dataScienceEnv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chowdhuryj\\AppData\\Local\\anaconda3\\envs\\dataScienceEnv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\chowdhuryj\\AppData\\Local\\anaconda3\\envs\\dataScienceEnv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# creating a dicationary \n",
    "data_categorical = {\n",
    "    'Variable Name': categorical_names,\n",
    "    'Test Statistic': statistic_list,\n",
    "    'P-Value': probability_list,\n",
    "    \"Statistically Significant\": hypothesis_list\n",
    "}\n",
    "\n",
    "# converting dicationary to data frame\n",
    "categorical_df = pd.DataFrame(data_categorical)\n",
    "\n",
    "# displaying the data frame as a table\n",
    "display(categorical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Two </font>\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html\n",
    "- https://www.geeksforgeeks.org/python-convert-two-lists-into-a-dictionary/\n",
    "- https://stackoverflow.com/questions/29530232/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe\n",
    "- https://stackoverflow.com/questions/73803147/find-the-row-numbers-in-a-dataframe-if-one-or-more-than-one-columns-in-a-row-h\n",
    "- https://stackoverflow.com/questions/44548721/remove-row-with-null-value-from-pandas-data-frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 3 </font> | Classification on Above Average Life Exepctancy\n",
    "In this section, we assess the relationship between various variables and above-average life expectancy at the US county level using the Kruskal-Wallis test for numerical variables and the $\\chi^2$ test for categorical variables. The results will be summarized in a table indicating the test statistic, p-value, and statistical signifigance at the 0.05 signifigance level for each variable. We achieve this by doing the following:\n",
    "- [ ] As above, run a Kruskal-Wallis test for each numerical variable versus the above average life-expectancy indicator. \n",
    "- [ ] We can test two categorical variables for association using a χ2 (read chi-squared) test of independence. To use the normal χ2 goodness of ﬁt test to check independence, expected frequencies of co-occurrences of the values from the two variables are calculated under the assumption that the values\n",
    "are independent. The χ2 test is then used to determine if the co-occurrence counts of the other data set match the expected independent distribution (null hypothesis). If the counts do not match, then you reject the null hypothesis of independence. The χ2 1Loosely speaking, two variables are independent if they have no relationship. \n",
    "- [ ] Run a χ2 test of independence between each categorical variable versus the above average life-expectancy indicator \n",
    "- [ ] In a single table, indicate the variable name, test statistic, p-value, and whether there is a statistically significant relationship between that variable and above average life-expectancy at a threshold of α = 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiating the lists to append to\n",
    "statistic_kw_list = []\n",
    "probability_kw_list = []\n",
    "hypothesis_kw_list = []\n",
    "\n",
    "# running the function in a for loop and storing the results\n",
    "for feature in dataframe_features:\n",
    "    \n",
    "    # retrieving all the necessary daya\n",
    "    t_value, p_value, r_value, statistical_signifigance = kruskal_wallis(county_df['life-expectancy'], feature)\n",
    "    \n",
    "    # appending to the instantiated lists\n",
    "    t_values_list.append(t_value)\n",
    "    p_values_list.append(p_value)\n",
    "    r_values_list.append(r_value)\n",
    "    signifigance_list.append(statistical_signifigance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Three </font>\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScienceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
