{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#d35400'> Lab 5 | Hypothesis Testing </font>\n",
    "Welcome to Lab 5! In this lab we work on hypothesis testing by implementing several different hypothesis tests from scratch and then comparing the results we get to the outputs of python functions. This lab explores using the World Health Organization (WHO) data which tracks a number of useful health-related metrics aggregated at the country level.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"dog_loves_sausages.jpeg\" alt=\"Alt Text\", width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> About the Dataset </font>\n",
    "We start off this Jupyter Notebook by first examining the dataset from `who2009.csv`. We look at the features that are in the dataset, as well as the data types being used in each of the features. We would like to get an idea of what we're dealing with, so we start off by displaying the dataset in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# importing the ipython library\n",
    "from IPython.display import display\n",
    "\n",
    "# read the .csv file using the pandas library\n",
    "who_df = pd.read_csv(\"who2009.csv\")\n",
    "\n",
    "# displaying the pandas dataframe\n",
    "who_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the descriptive statistics of the dataset\n",
    "display(\"Summary Statistics \", who_df.info())\n",
    "\n",
    "# displaying the summary of the dataset\n",
    "display(\"Description of Dataset\", who_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Dataset Information & Summary </font>\n",
    "According `.info()` and `.describe()`, we can see that there are 193 rows & 267 columns. With regards to te column headings on the dataset, they are presented as follows:\n",
    "- **Country:** Member State of the World Health Organization\n",
    "- **v9:** life expectancy at birth for both sexes\n",
    "- **v22:** infant mortality rate of both sexes\n",
    "- **v159:** health workforce\n",
    "- **v168:** hospital beds\n",
    "- **v174:** total expenditure on health as % of GDP\n",
    "- **v186:** out of pocket expenditure as % of private expenditure on health\n",
    "- **v192:** per capita total expenditure on health\n",
    "- **v249:** total fertility rate\n",
    "- **v259:** gross national income per capita \n",
    "- **regionname:** alphabetic ragion name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 1 </font> | Data Preparation\n",
    "In this section, we work on reading a `.csv` file in Pandas, and then perform some analysis, such as looking at the size of the dataset and understand what the features are by referring to the code book. We then rename the columns according to the code book. The instructions are arranged in the bullet points as follows:\n",
    "- [x] First read the who2009.csv ﬁle into your python development environment using pandas. You’ll need to import pandas and then apply the `.read csv` method.\n",
    "- [x] Assess the size of the data set using the .shape method. You should notice that there are a large number of columns in the data. We will only need a very small number of them. I have provided a codebook to go with this data (WHO2009SubsetCodebook.pdf). Drop columns from the data, keeping only those identiﬁed in the codebook.\n",
    "- [x] Rename the columns in the reduced data set to names that are appropriate descriptors of the information contained in each variable according to the codebook. You may ﬁnd the `.rename` method to be useful. Use the following variable names: `country`, `life exp`, `infant mortality`, `phys density`, `hospital bed`, `health exp` `percent GDP`, `OOP percent exp`, `health exp PC`, `fertility rate`, `GNI PC`, `regionname`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Finding the Shape of the Dataframe </font>\n",
    "We start off by finding the shape of the data frame, which means we get information as to how many rows and columns are in the dataset. Using `.shape` returns a tuple, where the first element is the number of rows and the second element is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the shape of the data frame and the rows and columns\n",
    "print(\"The Shape of the Dataframe: \", \"\\n\")\n",
    "print(\"Number of Rows: \", who_df.shape[0], \"\\n\")\n",
    "print(\"Number of Columns: \", who_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> The Codebook & Dropping the Data Columns </font>\n",
    "It can be seen in the dataset that there are large number of columns. We need a small number of them, so we drop the columns that are not mentioned in the codebook and keep the ones that are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of columns in the data set that are included in the code book\n",
    "col_list = [\"country\", \"v9\", \"v22\", \"v159\", \"v168\", \"v174\", \"v186\", \"v192\", \"v249\", \"v259\", \"regionname\"]\n",
    "\n",
    "# we take these columns of interest and create a new data frame\n",
    "new_who_df = who_df[col_list]\n",
    "\n",
    "# displaying the new data frame with the first 5 columns\n",
    "new_who_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Renaming the Data Columns </font>\n",
    "We can now work on renaming the data columns. We rename the data columns as follows:\n",
    "- `country` as `country`\n",
    "- `v9` as `life_exp`\n",
    "- `v22` as `infant_mortality`\n",
    "- `v159` as `phys_density`\n",
    "- `v168` as `hospital_bed`\n",
    "- `v174` as `health_exp_percent_GDP`\n",
    "- `v186` as `OOP_percent_exp`\n",
    "- `v192` as `health_exp_PC`\n",
    "- `v249` as `fertility_rate`\n",
    "- `v259` as `GNI_PC`\n",
    "- `regionname` as `regionname`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns as mentioned in the code book\n",
    "new_who_df = new_who_df.rename(columns={'v9' : 'life_exp', 'v22' : 'infant_mortality', 'v159' : 'phys_density'})\n",
    "new_who_df = new_who_df.rename(columns={'v168' : 'hospital_bed', 'v174' : 'health_exp_percent_gdp'})\n",
    "new_who_df = new_who_df.rename(columns={'v186' : 'OOP_percent_exp', 'v192' : 'health_exp_PC'})\n",
    "new_who_df = new_who_df.rename(columns={'v249' : 'fertility_rate', 'v259' : 'GNI_PC'})\n",
    "\n",
    "# displaying the new data frame with renamed columns\n",
    "new_who_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section One </font>\n",
    "- https://stackoverflow.com/questions/16616141/keep-certain-columns-in-a-pandas-dataframe-deleting-everything-else\n",
    "- https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 2 | One Sample T-test </font>\n",
    "The purpose of a one sample t-test is meant to  compare a numerical variable against a fixed number. In this section, we assess the life expectancy in Europe by creating a new data set. We achieve this creating a new function that takes in data and a value, and then returns the test-statistic p-value as outputs. We use that function to then to assess whether the life expectancy in Europe is different from 70 and 76 years, and then compare them using `scipy.stats`. We achieve this in the following bullet points:\n",
    "\n",
    "- [x] Begin by creating a second data set that includes only rows in which the regionname is \"Europe\"\n",
    "- [x] The test statistic in a one sample t-test is shown below, where s is the standard deviation and where $\\mu$ is the sample mean, n is the number of observations in the sample, $x_i$ is the value of the variable for the i-th observation, and M is the number chosen in this jupyter notebook. The p-value is found using the formula below.\n",
    "- [x] Write a function to assess whether the life expectancy in Europe is significantly different from 70 and 76 years\n",
    "- [x] Validate the code by comparing the results to the built-in one-sample t-test. We achieve this by using the `ttest_1samp` method from `scipy.stats`.\n",
    "\n",
    "### <font color = '#FF8C00'> Formulas </font>\n",
    "$$\n",
    "t = \\frac{\\mu - M}{s / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\mu)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p = 2(1 - P(|t|))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Filtering Out Europe </font>\n",
    "We start off by focusing on the `regionname` column. We would like to filter out the places which belong in the Europe region, and find more details about the features we filtered out for those countries that belong in that region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the second dataset where the region name is only \"Europe\"\n",
    "europe_df = new_who_df[new_who_df[\"regionname\"] == \"Europe\"]\n",
    "\n",
    "# displaying the europe data frame of the top 5\n",
    "europe_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Building the Function </font>\n",
    "Next, we move on to building out function using the formulas mentioned above. The function is designed to take the data and the value M as inputs and returns the test statistic and p-value as outputs. \n",
    "\n",
    "We work with the CDF of the t-dsitribution. From scipy.stats, we import t to load the t-distribution and then work with `t.cdf` with the degrees of freedom set to `n-1`. The `.mean` and `.std` methods from `numpy` are helpful, but be sure to use `ddof` = 1 if we use `.std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import t\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the t-test function\n",
    "def one_smaple_t_test(feature_col, input_value):\n",
    "\n",
    "    # converting the column into a list\n",
    "    feature_list = feature_col.tolist()\n",
    "\n",
    "    # calculating the mean\n",
    "    feature_mean = np.mean(feature_col)\n",
    "\n",
    "    # finding number of observations and square root it\n",
    "    observation = len(feature_col)\n",
    "    sqrt_observation = math.sqrt(observation)\n",
    "\n",
    "    # (observation - mean) ^ 2\n",
    "    difference_list = []\n",
    "    for row in range(0, len(feature_list)):\n",
    "        difference = (feature_list[row] - feature_mean)**2\n",
    "        difference_list.append(difference)\n",
    "    \n",
    "    # finding the sum of the differences\n",
    "    sum_of_differences = sum(difference_list)\n",
    "\n",
    "    # calculating the variance\n",
    "    variance = sum_of_differences * (1 / (observation - 1))\n",
    "\n",
    "    # calculating the standard deviation\n",
    "    standard_deviation = math.sqrt(variance)\n",
    "\n",
    "    # calculating the t-value\n",
    "    t_value = (feature_mean - input_value) / (standard_deviation / sqrt_observation)\n",
    "\n",
    "    # calculating the p-value\n",
    "    p_value = 2 * (1- t.cdf(abs(t_value), observation - 1))\n",
    "\n",
    "    # returning t value and p value\n",
    "    return t_value, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Life Expectancy </font>\n",
    "We now use the function that we built to compare the life expectancy in Europe is different from 70 years compared to 76 years. The function will then return the t value and the p value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the function where input_value is 70 as in 70 years\n",
    "t_value_seventy, p_value_seventy = one_smaple_t_test(europe_df['life_exp'], 70)\n",
    "print(\"The t value for Life Expectancy of 70: \", t_value_seventy, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 70: \", p_value_seventy, \"\\n\" )\n",
    "\n",
    "# running the function where input_value is 76 as in 76 years\n",
    "t_value_seventy_six, p_value_seventy_six = one_smaple_t_test(europe_df['life_exp'], 76)\n",
    "print(\"The t value for Life Expectancy of 76: \", t_value_seventy_six, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 76: \", p_value_seventy_six, \"\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Validating the Function </font>\n",
    "We now work on validating the function. Using the results we obtained in the previous python cell, we now compare our results with what we derive using the `scipy.stats` library, using the `ttest_1samp` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_value_seventy, pp_value_seventy = ttest_1samp(europe_df['life_exp'], 70)\n",
    "print(\"The t value for Life Expectancy of 70: \", tt_value_seventy, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 70: \", pp_value_seventy, \"\\n\")\n",
    "\n",
    "tt_value_seventy_six, pp_value_seventy_six = ttest_1samp(europe_df['life_exp'], 76)\n",
    "print(\"The t value for Life Expectancy of 76: \", tt_value_seventy_six, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 76: \", pp_value_seventy_six, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Two </font>\n",
    "- https://www.geeksforgeeks.org/ways-to-filter-pandas-dataframe-by-column-values/\n",
    "- https://sparkbyexamples.com/pandas/pandas-filter-rows-by-conditions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 2 | Two Sample T-test </font>\n",
    "A two-sample t-test is meant to compare a numerical variable against a categorical variable. The goal is to assess whether the numerical variable is \"different\" across the categories. In this section, we compare the life expectancy in Europe against the life expectancy in Asia. We achieve this in the following steps below:\n",
    "- [x] Create a third data set that includes only rows in which regionname is “Asia.”\n",
    "- [x] The test statistic is shown in the formula section below. The p-values are also computed using the degrees of freedom, which is calculated using the formula below. \n",
    "- [x] Write a function that takes two data set inputs and returns the test statistic and p-values as outputs\n",
    "- [ ] We then use the function we built to assess whether the life expetancy in Europe is different than the life expectancy in Asia\n",
    "- [ ] We then validate the function by comparing the results to the built-in two sample t-test using the the `ttest_ind` method from `scipy.stats`.\n",
    "\n",
    "\n",
    "### <font color = '#FF8C00'> Formulas </font>\n",
    "$$\n",
    "t = \\frac{\\mu_1 - \\mu_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nu = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}\n",
    "{\\frac{s_1^4}{n_1^2 (n_1 - 1)} + \\frac{s_2^4}{n_2^2 (n_2 - 1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Filtering Out Asia </font>\n",
    "We start off by using the `new_world_df` data frame to filter out rows of data whose `regionname` is Asia. We would like to collect all the features and the data they have for each corresponding row to perform the two sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the rows that have the regionname set as Asia\n",
    "asia_df = new_who_df[new_who_df['regionname'] == \"Asia\"]\n",
    "\n",
    "# displaying the data frame with just the top 5\n",
    "asia_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Building the Function </font>\n",
    "We build this function so that it takes two data sets as inputs and returns the test statistic and p-value as outputs. We implement the formulas mentioned above to help calculate the degrees of freedom, the test statistic and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function for the two sample t-test\n",
    "def two_sample_t_test(feature_col_one, feature_col_two):\n",
    "\n",
    "    # converting the feature into a list\n",
    "    feature_list_one = feature_col_one.tolist()\n",
    "    feature_list_two = feature_col_two.tolist()\n",
    "\n",
    "    # calculating the mean from the two features\n",
    "    mean_one = sum(feature_list_one) / len(feature_list_one)\n",
    "    mean_two = sum(feature_list_two) / len(feature_list_two)\n",
    "\n",
    "    # number of observations in each feature\n",
    "    observation_one = len(feature_list_one)\n",
    "    observation_two = len(feature_list_two)\n",
    "\n",
    "    # (observation - mean) ^ 2 for dataset one\n",
    "    difference_list_one = []\n",
    "    for row_one in range(0, len(feature_list_one)):\n",
    "        difference_one = (feature_list_one[row_one] - mean_one)**2\n",
    "        difference_list_one.append(difference_one)\n",
    "    \n",
    "    # (observation - mean) ^ 2 for dataset two\n",
    "    difference_list_two = []\n",
    "    for row_two in range(0, len(feature_list_two)):\n",
    "        difference_two = (feature_list_two[row_two] - mean_two)**2\n",
    "        difference_list_two.append(difference_two)\n",
    "    \n",
    "    # finding the sum of the different list one and two\n",
    "    sum_one = sum(difference_list_one)\n",
    "    sum_two = sum(difference_list_two)\n",
    "\n",
    "    # calculating the variance one and two\n",
    "    variance_one = sum_one / (observation_one - 1)\n",
    "    variance_two = sum_two / (observation_two - 1)\n",
    "\n",
    "    # calculating the standard deviation one and two\n",
    "    standard_deviation_one = math.sqrt(variance_one)\n",
    "    standard_deviation_two = math.sqrt(variance_two)\n",
    "\n",
    "    # calculating the numerator of the degrees of freedom\n",
    "    numerator = ((standard_deviation_one**2 / observation_one) + (standard_deviation_two**2 / observation_two))**2\n",
    "\n",
    "    # calculating the denominator part one\n",
    "    denominator_part_one = (standard_deviation_one**4) / ((observation_one**2) * (observation_one - 1))\n",
    "    denominator_part_two = (standard_deviation_two**4) / ((observation_two**2) * (observation_two - 1))\n",
    "    denominator = denominator_part_one + denominator_part_two\n",
    "\n",
    "    # calculating the degree of freedom\n",
    "    degree_of_freedom = numerator / denominator\n",
    "\n",
    "    # calculating the test statistic\n",
    "    t_value = (mean_one - mean_two) / math.sqrt((standard_deviation_one**2 / observation_one) + \n",
    "                                                (standard_deviation_two**2 / observation_two))\n",
    "    \n",
    "    # calculating the p value\n",
    "    p_value = 2 * (1 - t.cdf(abs(t_value), degree_of_freedom))\n",
    "\n",
    "    # returning the t_value and p_value\n",
    "    return t_value, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Life Expectancy in Europe vs Asia </font>\n",
    "We now calculate and compare the life expectancy in Europe vs in Asia. We do this by accessing the `life_exp` feature from both the data frames of Asia `asia_df` and Europe `europe_df`. We then take these features and put it into the function and get the t_value and p_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function to retrieve the t_value and p_value\n",
    "t_value, p_value = two_sample_t_test(asia_df[\"life_exp\"], europe_df[\"life_exp\"])\n",
    "print(\"The test statistic value of Life Expectancy in Europe vs Asia: \", t_value, \"\\n\")\n",
    "print(\"The p value of Life Expectancy of Europe vs Asia: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Validating the Function </font>\n",
    "We now work on validating the function. We achieve this by using the `ttest_ind` method from the `scipy.stats` library. We then use the values we get from the method, to compare against the function we created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the scipy.stats library\n",
    "from scipy import stats\n",
    "\n",
    "# running the ttest_ind method from the scipy.stats library\n",
    "t_value, p_value = stats.ttest_ind(a=asia_df[\"life_exp\"], b=europe_df[\"life_exp\"], equal_var=False)\n",
    "\n",
    "# printing out the test statistic and p value\n",
    "print(\"The Test Statistics of Life Expectancy in Europe vs Asia: \", t_value, \"\\n\")\n",
    "print(\"The p Value of Life Expectancy in Europe vs Asia: \", p_value, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Three </font>\n",
    "- https://www.geeksforgeeks.org/how-to-conduct-a-two-sample-t-test-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScienceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
