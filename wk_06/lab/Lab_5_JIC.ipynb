{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#d35400'> Lab 5 | Hypothesis Testing </font>\n",
    "Welcome to Lab 5! In this lab we work on hypothesis testing by implementing several different hypothesis tests from scratch and then comparing the results we get to the outputs of python functions. This lab explores using the World Health Organization (WHO) data which tracks a number of useful health-related metrics aggregated at the country level.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"dog_loves_sausages.jpeg\" alt=\"Alt Text\", width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> About the Dataset </font>\n",
    "We start off this Jupyter Notebook by first examining the dataset from `who2009.csv`. We look at the features that are in the dataset, as well as the data types being used in each of the features. We would like to get an idea of what we're dealing with, so we start off by displaying the dataset in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v257</th>\n",
       "      <th>v258</th>\n",
       "      <th>v259</th>\n",
       "      <th>v260</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>iso3</th>\n",
       "      <th>regioncode</th>\n",
       "      <th>regionname</th>\n",
       "      <th>subregioncode</th>\n",
       "      <th>subregionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>AFG</td>\n",
       "      <td>142</td>\n",
       "      <td>Asia</td>\n",
       "      <td>34</td>\n",
       "      <td>Southern Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>ALB</td>\n",
       "      <td>150</td>\n",
       "      <td>Europe</td>\n",
       "      <td>39</td>\n",
       "      <td>Southern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>15</td>\n",
       "      <td>Northern Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>150</td>\n",
       "      <td>Europe</td>\n",
       "      <td>39</td>\n",
       "      <td>Southern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>24</td>\n",
       "      <td>AGO</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>17</td>\n",
       "      <td>Middle Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Venezuela (Bolivarian Republic of)</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>6820.0</td>\n",
       "      <td>8380.0</td>\n",
       "      <td>11920.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>862</td>\n",
       "      <td>VEN</td>\n",
       "      <td>19</td>\n",
       "      <td>Americas</td>\n",
       "      <td>5</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>704</td>\n",
       "      <td>VNM</td>\n",
       "      <td>142</td>\n",
       "      <td>Asia</td>\n",
       "      <td>35</td>\n",
       "      <td>South-Eastern Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>887</td>\n",
       "      <td>YEM</td>\n",
       "      <td>142</td>\n",
       "      <td>Asia</td>\n",
       "      <td>145</td>\n",
       "      <td>Western Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>820.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>894</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>14</td>\n",
       "      <td>Eastern Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>716</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>14</td>\n",
       "      <td>Eastern Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                country  v1  v2  v3  v4  v5  v6  v7  v8  v9  \\\n",
       "0                           Afghanistan  41  40  41  42  42  42  42  41  42   \n",
       "1                               Albania  66  68  71  71  73  74  69  71  72   \n",
       "2                               Algeria  65  68  70  68  71  73  66  70  71   \n",
       "3                               Andorra  74  76  78  81  83  85  77  80  81   \n",
       "4                                Angola  38  46  51  44  51  55  41  49  53   \n",
       "..                                  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "188  Venezuela (Bolivarian Republic of)  70  71  72  74  77  78  72  74  75   \n",
       "189                            Viet Nam  64  68  70  68  72  75  66  70  72   \n",
       "190                               Yemen  56  59  62  59  63  66  58  61  64   \n",
       "191                              Zambia  52  41  45  55  44  47  53  42  46   \n",
       "192                            Zimbabwe  57  43  45  63  46  44  60  44  45   \n",
       "\n",
       "     ...    v257    v258     v259  v260  countrycode  iso3  regioncode  \\\n",
       "0    ...     NaN     NaN      NaN   NaN            4   AFG         142   \n",
       "1    ...  2540.0  3920.0   6580.0   1.0            8   ALB         150   \n",
       "2    ...  4350.0  5130.0   7640.0   NaN           12   DZA           2   \n",
       "3    ...     NaN     NaN      NaN   NaN           20   AND         150   \n",
       "4    ...  1870.0  1910.0   4400.0  42.5           24   AGO           2   \n",
       "..   ...     ...     ...      ...   ...          ...   ...         ...   \n",
       "188  ...  6820.0  8380.0  11920.0  10.0          862   VEN          19   \n",
       "189  ...   610.0  1400.0   2550.0  22.8          704   VNM         142   \n",
       "190  ...  1280.0  1710.0   2200.0  17.5          887   YEM         142   \n",
       "191  ...   820.0   870.0   1220.0  64.3          894   ZMB           2   \n",
       "192  ...     NaN     NaN      NaN   NaN          716   ZWE           2   \n",
       "\n",
       "     regionname  subregioncode       subregionname  \n",
       "0          Asia             34       Southern Asia  \n",
       "1        Europe             39     Southern Europe  \n",
       "2        Africa             15     Northern Africa  \n",
       "3        Europe             39     Southern Europe  \n",
       "4        Africa             17       Middle Africa  \n",
       "..          ...            ...                 ...  \n",
       "188    Americas              5       South America  \n",
       "189        Asia             35  South-Eastern Asia  \n",
       "190        Asia            145        Western Asia  \n",
       "191      Africa             14      Eastern Africa  \n",
       "192      Africa             14      Eastern Africa  \n",
       "\n",
       "[193 rows x 267 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# importing the ipython library\n",
    "from IPython.display import display\n",
    "\n",
    "# read the .csv file using the pandas library\n",
    "who_df = pd.read_csv(\"who2009.csv\")\n",
    "\n",
    "# displaying the pandas dataframe\n",
    "who_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Columns: 267 entries, country to subregionname\n",
      "dtypes: float64(209), int64(53), object(5)\n",
      "memory usage: 402.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Summary Statistics '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Description of Dataset'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v254</th>\n",
       "      <th>v255</th>\n",
       "      <th>v256</th>\n",
       "      <th>v257</th>\n",
       "      <th>v258</th>\n",
       "      <th>v259</th>\n",
       "      <th>v260</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>regioncode</th>\n",
       "      <th>subregioncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.145078</td>\n",
       "      <td>63.860104</td>\n",
       "      <td>65.502591</td>\n",
       "      <td>67.310881</td>\n",
       "      <td>68.875648</td>\n",
       "      <td>70.274611</td>\n",
       "      <td>64.626943</td>\n",
       "      <td>66.367876</td>\n",
       "      <td>67.839378</td>\n",
       "      <td>58.595855</td>\n",
       "      <td>...</td>\n",
       "      <td>87.128834</td>\n",
       "      <td>81.491935</td>\n",
       "      <td>84.902439</td>\n",
       "      <td>5999.869281</td>\n",
       "      <td>8424.825581</td>\n",
       "      <td>12026.742857</td>\n",
       "      <td>25.901075</td>\n",
       "      <td>431.181347</td>\n",
       "      <td>71.963731</td>\n",
       "      <td>83.777202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.752654</td>\n",
       "      <td>9.834363</td>\n",
       "      <td>9.813428</td>\n",
       "      <td>10.199404</td>\n",
       "      <td>10.690975</td>\n",
       "      <td>10.754952</td>\n",
       "      <td>9.956975</td>\n",
       "      <td>10.207963</td>\n",
       "      <td>10.223548</td>\n",
       "      <td>9.363181</td>\n",
       "      <td>...</td>\n",
       "      <td>13.090920</td>\n",
       "      <td>20.795362</td>\n",
       "      <td>17.016852</td>\n",
       "      <td>7204.320249</td>\n",
       "      <td>10187.348849</td>\n",
       "      <td>13386.001361</td>\n",
       "      <td>25.445049</td>\n",
       "      <td>254.403312</td>\n",
       "      <td>68.744195</td>\n",
       "      <td>106.063990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1427.500000</td>\n",
       "      <td>2220.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>2970.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>6580.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>8100.000000</td>\n",
       "      <td>9860.000000</td>\n",
       "      <td>16515.000000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38760.000000</td>\n",
       "      <td>46510.000000</td>\n",
       "      <td>63590.000000</td>\n",
       "      <td>86.100000</td>\n",
       "      <td>894.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               v1          v2          v3          v4          v5          v6  \\\n",
       "count  193.000000  193.000000  193.000000  193.000000  193.000000  193.000000   \n",
       "mean    62.145078   63.860104   65.502591   67.310881   68.875648   70.274611   \n",
       "std      9.752654    9.834363    9.813428   10.199404   10.690975   10.754952   \n",
       "min     25.000000   34.000000   39.000000   37.000000   42.000000   42.000000   \n",
       "25%     57.000000   57.000000   58.000000   61.000000   62.000000   63.000000   \n",
       "50%     64.000000   66.000000   67.000000   70.000000   73.000000   74.000000   \n",
       "75%     69.000000   71.000000   72.000000   75.000000   77.000000   78.000000   \n",
       "max     76.000000   78.000000   81.000000   82.000000   85.000000   86.000000   \n",
       "\n",
       "               v7          v8          v9         v10  ...        v254  \\\n",
       "count  193.000000  193.000000  193.000000  193.000000  ...  163.000000   \n",
       "mean    64.626943   66.367876   67.839378   58.595855  ...   87.128834   \n",
       "std      9.956975   10.207963   10.223548    9.363181  ...   13.090920   \n",
       "min     31.000000   38.000000   41.000000   34.000000  ...   32.000000   \n",
       "25%     58.000000   60.000000   61.000000   52.000000  ...   83.500000   \n",
       "50%     67.000000   70.000000   71.000000   60.000000  ...   91.000000   \n",
       "75%     72.000000   74.000000   75.000000   65.000000  ...   96.000000   \n",
       "max     79.000000   81.000000   83.000000   74.000000  ...  100.000000   \n",
       "\n",
       "             v255        v256          v257          v258          v259  \\\n",
       "count  124.000000  164.000000    153.000000    172.000000    175.000000   \n",
       "mean    81.491935   84.902439   5999.869281   8424.825581  12026.742857   \n",
       "std     20.795362   17.016852   7204.320249  10187.348849  13386.001361   \n",
       "min     21.000000    0.000000    250.000000    210.000000    290.000000   \n",
       "25%     77.000000   82.000000   1190.000000   1427.500000   2220.000000   \n",
       "50%     90.500000   90.500000   2970.000000   4385.000000   6580.000000   \n",
       "75%     96.000000   96.000000   8100.000000   9860.000000  16515.000000   \n",
       "max    100.000000  100.000000  38760.000000  46510.000000  63590.000000   \n",
       "\n",
       "            v260  countrycode  regioncode  subregioncode  \n",
       "count  93.000000   193.000000  193.000000     193.000000  \n",
       "mean   25.901075   431.181347   71.963731      83.777202  \n",
       "std    25.445049   254.403312   68.744195     106.063990  \n",
       "min     0.000000     4.000000    2.000000       5.000000  \n",
       "25%     1.200000   208.000000    2.000000      14.000000  \n",
       "50%    19.700000   428.000000   19.000000      35.000000  \n",
       "75%    46.100000   646.000000  142.000000     145.000000  \n",
       "max    86.100000   894.000000  150.000000     419.000000  \n",
       "\n",
       "[8 rows x 262 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying the descriptive statistics of the dataset\n",
    "display(\"Summary Statistics \", who_df.info())\n",
    "\n",
    "# displaying the summary of the dataset\n",
    "display(\"Description of Dataset\", who_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Dataset Information & Summary </font>\n",
    "According `.info()` and `.describe()`, we can see that there are 193 rows & 267 columns. With regards to te column headings on the dataset, they are presented as follows:\n",
    "- **Country:** Member State of the World Health Organization\n",
    "- **v9:** life expectancy at birth for both sexes\n",
    "- **v22:** infant mortality rate of both sexes\n",
    "- **v159:** health workforce\n",
    "- **v168:** hospital beds\n",
    "- **v174:** total expenditure on health as % of GDP\n",
    "- **v186:** out of pocket expenditure as % of private expenditure on health\n",
    "- **v192:** per capita total expenditure on health\n",
    "- **v249:** total fertility rate\n",
    "- **v259:** gross national income per capita \n",
    "- **regionname:** alphabetic ragion name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 1 </font> | Data Preparation\n",
    "In this section, we work on reading a `.csv` file in Pandas, and then perform some analysis, such as looking at the size of the dataset and understand what the features are by referring to the code book. We then rename the columns according to the code book. The instructions are arranged in the bullet points as follows:\n",
    "- [x] First read the who2009.csv ﬁle into your python development environment using pandas. You’ll need to import pandas and then apply the `.read csv` method.\n",
    "- [x] Assess the size of the data set using the .shape method. You should notice that there are a large number of columns in the data. We will only need a very small number of them. I have provided a codebook to go with this data (WHO2009SubsetCodebook.pdf). Drop columns from the data, keeping only those identiﬁed in the codebook.\n",
    "- [x] Rename the columns in the reduced data set to names that are appropriate descriptors of the information contained in each variable according to the codebook. You may ﬁnd the `.rename` method to be useful. Use the following variable names: `country`, `life exp`, `infant mortality`, `phys density`, `hospital bed`, `health exp` `percent GDP`, `OOP percent exp`, `health exp PC`, `fertility rate`, `GNI PC`, `regionname`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Finding the Shape of the Dataframe </font>\n",
    "We start off by finding the shape of the data frame, which means we get information as to how many rows and columns are in the dataset. Using `.shape` returns a tuple, where the first element is the number of rows and the second element is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataframe:  \n",
      "\n",
      "Number of Rows:  193 \n",
      "\n",
      "Number of Columns:  267\n"
     ]
    }
   ],
   "source": [
    "# printing out the shape of the data frame and the rows and columns\n",
    "print(\"The Shape of the Dataframe: \", \"\\n\")\n",
    "print(\"Number of Rows: \", who_df.shape[0], \"\\n\")\n",
    "print(\"Number of Columns: \", who_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> The Codebook & Dropping the Data Columns </font>\n",
    "It can be seen in the dataset that there are large number of columns. We need a small number of them, so we drop the columns that are not mentioned in the codebook and keep the ones that are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>v9</th>\n",
       "      <th>v22</th>\n",
       "      <th>v159</th>\n",
       "      <th>v168</th>\n",
       "      <th>v174</th>\n",
       "      <th>v186</th>\n",
       "      <th>v192</th>\n",
       "      <th>v249</th>\n",
       "      <th>v259</th>\n",
       "      <th>regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>78.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>94.9</td>\n",
       "      <td>381.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>71</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>94.6</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>73.4</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>53</td>\n",
       "      <td>116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  v9  v22  v159  v168  v174   v186    v192  v249    v259  \\\n",
       "0  Afghanistan  42  165   2.0   4.0   9.2   78.5    91.0   7.1     NaN   \n",
       "1      Albania  72   13  12.0  30.0   6.5   94.9   381.0   2.1  6580.0   \n",
       "2      Algeria  71   33  11.0  17.0   4.2   94.6   315.0   2.4  7640.0   \n",
       "3      Andorra  81    3  36.0  32.0   7.4   73.4  2980.0   1.3     NaN   \n",
       "4       Angola  53  116   1.0   8.0   2.6  100.0   115.0   6.5  4400.0   \n",
       "\n",
       "  regionname  \n",
       "0       Asia  \n",
       "1     Europe  \n",
       "2     Africa  \n",
       "3     Europe  \n",
       "4     Africa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the list of columns in the data set that are included in the code book\n",
    "col_list = [\"country\", \"v9\", \"v22\", \"v159\", \"v168\", \"v174\", \"v186\", \"v192\", \"v249\", \"v259\", \"regionname\"]\n",
    "\n",
    "# we take these columns of interest and create a new data frame\n",
    "new_who_df = who_df[col_list]\n",
    "\n",
    "# displaying the new data frame with the first 5 columns\n",
    "new_who_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Renaming the Data Columns </font>\n",
    "We can now work on renaming the data columns. We rename the data columns as follows:\n",
    "- `country` as `country`\n",
    "- `v9` as `life_exp`\n",
    "- `v22` as `infant_mortality`\n",
    "- `v159` as `phys_density`\n",
    "- `v168` as `hospital_bed`\n",
    "- `v174` as `health_exp_percent_GDP`\n",
    "- `v186` as `OOP_percent_exp`\n",
    "- `v192` as `health_exp_PC`\n",
    "- `v249` as `fertility_rate`\n",
    "- `v259` as `GNI_PC`\n",
    "- `regionname` as `regionname`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>life_exp</th>\n",
       "      <th>infant_mortality</th>\n",
       "      <th>phys_density</th>\n",
       "      <th>hospital_bed</th>\n",
       "      <th>health_exp_percent_gdp</th>\n",
       "      <th>OOP_percent_exp</th>\n",
       "      <th>health_exp_PC</th>\n",
       "      <th>fertility_rate</th>\n",
       "      <th>GNI_PC</th>\n",
       "      <th>regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>78.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>94.9</td>\n",
       "      <td>381.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>71</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>94.6</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>73.4</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>53</td>\n",
       "      <td>116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  life_exp  infant_mortality  phys_density  hospital_bed  \\\n",
       "0  Afghanistan        42               165           2.0           4.0   \n",
       "1      Albania        72                13          12.0          30.0   \n",
       "2      Algeria        71                33          11.0          17.0   \n",
       "3      Andorra        81                 3          36.0          32.0   \n",
       "4       Angola        53               116           1.0           8.0   \n",
       "\n",
       "   health_exp_percent_gdp  OOP_percent_exp  health_exp_PC  fertility_rate  \\\n",
       "0                     9.2             78.5           91.0             7.1   \n",
       "1                     6.5             94.9          381.0             2.1   \n",
       "2                     4.2             94.6          315.0             2.4   \n",
       "3                     7.4             73.4         2980.0             1.3   \n",
       "4                     2.6            100.0          115.0             6.5   \n",
       "\n",
       "   GNI_PC regionname  \n",
       "0     NaN       Asia  \n",
       "1  6580.0     Europe  \n",
       "2  7640.0     Africa  \n",
       "3     NaN     Europe  \n",
       "4  4400.0     Africa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the columns as mentioned in the code book\n",
    "new_who_df = new_who_df.rename(columns={'v9' : 'life_exp', 'v22' : 'infant_mortality', 'v159' : 'phys_density'})\n",
    "new_who_df = new_who_df.rename(columns={'v168' : 'hospital_bed', 'v174' : 'health_exp_percent_gdp'})\n",
    "new_who_df = new_who_df.rename(columns={'v186' : 'OOP_percent_exp', 'v192' : 'health_exp_PC'})\n",
    "new_who_df = new_who_df.rename(columns={'v249' : 'fertility_rate', 'v259' : 'GNI_PC'})\n",
    "\n",
    "# displaying the new data frame with renamed columns\n",
    "new_who_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section One </font>\n",
    "- https://stackoverflow.com/questions/16616141/keep-certain-columns-in-a-pandas-dataframe-deleting-everything-else\n",
    "- https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 2 | One Sample T-test </font>\n",
    "The purpose of a one sample t-test is meant to  compare a numerical variable against a fixed number. In this section, we assess the life expectancy in Europe by creating a new data set. We achieve this creating a new function that takes in data and a value, and then returns the test-statistic p-value as outputs. We use that function to then to assess whether the life expectancy in Europe is different from 70 and 76 years, and then compare them using `scipy.stats`. We achieve this in the following bullet points:\n",
    "\n",
    "- [x] Begin by creating a second data set that includes only rows in which the regionname is \"Europe\"\n",
    "- [x] The test statistic in a one sample t-test is shown below, where s is the standard deviation and where $\\mu$ is the sample mean, n is the number of observations in the sample, $x_i$ is the value of the variable for the i-th observation, and M is the number chosen in this jupyter notebook. The p-value is found using the formula below.\n",
    "- [x] Write a function to assess whether the life expectancy in Europe is significantly different from 70 and 76 years\n",
    "- [x] Validate the code by comparing the results to the built-in one-sample t-test. We achieve this by using the `ttest_1samp` method from `scipy.stats`.\n",
    "\n",
    "### <font color = '#FF8C00'> Formulas </font>\n",
    "$$\n",
    "t = \\frac{\\mu - M}{s / \\sqrt{n}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\mu)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p = 2(1 - P(|t|))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Filtering Out Europe </font>\n",
    "We start off by focusing on the `regionname` column. We would like to filter out the places which belong in the Europe region, and find more details about the features we filtered out for those countries that belong in that region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>life_exp</th>\n",
       "      <th>infant_mortality</th>\n",
       "      <th>phys_density</th>\n",
       "      <th>hospital_bed</th>\n",
       "      <th>health_exp_percent_gdp</th>\n",
       "      <th>OOP_percent_exp</th>\n",
       "      <th>health_exp_PC</th>\n",
       "      <th>fertility_rate</th>\n",
       "      <th>GNI_PC</th>\n",
       "      <th>regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>94.9</td>\n",
       "      <td>381.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>73.4</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Austria</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>65.8</td>\n",
       "      <td>3608.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>38140.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>68.8</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10740.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>34790.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  life_exp  infant_mortality  phys_density  hospital_bed  \\\n",
       "1   Albania        72                13          12.0          30.0   \n",
       "3   Andorra        81                 3          36.0          32.0   \n",
       "9   Austria        80                 4          37.0          76.0   \n",
       "15  Belarus        70                 5          48.0         113.0   \n",
       "16  Belgium        80                 4          42.0          53.0   \n",
       "\n",
       "    health_exp_percent_gdp  OOP_percent_exp  health_exp_PC  fertility_rate  \\\n",
       "1                      6.5             94.9          381.0             2.1   \n",
       "3                      7.4             73.4         2980.0             1.3   \n",
       "9                     10.2             65.8         3608.0             1.4   \n",
       "15                     6.4             68.8          623.0             1.2   \n",
       "16                     9.9             79.0            4.0             1.6   \n",
       "\n",
       "     GNI_PC regionname  \n",
       "1    6580.0     Europe  \n",
       "3       NaN     Europe  \n",
       "9   38140.0     Europe  \n",
       "15  10740.0     Europe  \n",
       "16  34790.0     Europe  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the second dataset where the region name is only \"Europe\"\n",
    "europe_df = new_who_df[new_who_df[\"regionname\"] == \"Europe\"]\n",
    "\n",
    "# displaying the europe data frame of the top 5\n",
    "europe_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Building the Function </font>\n",
    "Next, we move on to building out function using the formulas mentioned above. The function is designed to take the data and the value M as inputs and returns the test statistic and p-value as outputs. \n",
    "\n",
    "We work with the CDF of the t-dsitribution. From scipy.stats, we import t to load the t-distribution and then work with `t.cdf` with the degrees of freedom set to `n-1`. The `.mean` and `.std` methods from `numpy` are helpful, but be sure to use `ddof` = 1 if we use `.std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import t\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the t-test function\n",
    "def one_smaple_t_test(feature_col, input_value):\n",
    "\n",
    "    # converting the column into a list\n",
    "    feature_list = feature_col.tolist()\n",
    "\n",
    "    # calculating the mean\n",
    "    feature_mean = np.mean(feature_col)\n",
    "\n",
    "    # finding number of observations and square root it\n",
    "    observation = len(feature_col)\n",
    "    sqrt_observation = math.sqrt(observation)\n",
    "\n",
    "    # (observation - mean) ^ 2\n",
    "    difference_list = []\n",
    "    for row in range(0, len(feature_list)):\n",
    "        difference = (feature_list[row] - feature_mean)**2\n",
    "        difference_list.append(difference)\n",
    "    \n",
    "    # finding the sum of the differences\n",
    "    sum_of_differences = sum(difference_list)\n",
    "\n",
    "    # calculating the variance\n",
    "    variance = sum_of_differences * (1 / (observation - 1))\n",
    "\n",
    "    # calculating the standard deviation\n",
    "    standard_deviation = math.sqrt(variance)\n",
    "\n",
    "    # calculating the t-value\n",
    "    t_value = (feature_mean - input_value) / (standard_deviation / sqrt_observation)\n",
    "\n",
    "    # calculating the p-value\n",
    "    p_value = 2 * (1- t.cdf(abs(t_value), observation - 1))\n",
    "\n",
    "    # returning t value and p value\n",
    "    return t_value, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Life Expectancy </font>\n",
    "We now use the function that we built to compare the life expectancy in Europe is different from 70 years compared to 76 years. The function will then return the t value and the p value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t value for Life Expectancy of 70:  9.938016169764737 \n",
      "\n",
      "The p value for Life Expectancy of 70:  1.7605916724505732e-12 \n",
      "\n",
      "The t value for Life Expectancy of 76:  1.1814424817202844 \n",
      "\n",
      "The p value for Life Expectancy of 76:  0.24423470312189988 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the function where input_value is 70 as in 70 years\n",
    "t_value_seventy, p_value_seventy = one_smaple_t_test(europe_df['life_exp'], 70)\n",
    "print(\"The t value for Life Expectancy of 70: \", t_value_seventy, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 70: \", p_value_seventy, \"\\n\" )\n",
    "\n",
    "# running the function where input_value is 76 as in 76 years\n",
    "t_value_seventy_six, p_value_seventy_six = one_smaple_t_test(europe_df['life_exp'], 76)\n",
    "print(\"The t value for Life Expectancy of 76: \", t_value_seventy_six, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 76: \", p_value_seventy_six, \"\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Validating the Function </font>\n",
    "We now work on validating the function. Using the results we obtained in the previous python cell, we now compare our results with what we derive using the `scipy.stats` library, using the `ttest_1samp` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t value for Life Expectancy of 70:  9.938016169764737 \n",
      "\n",
      "The p value for Life Expectancy of 70:  1.760564922569916e-12 \n",
      "\n",
      "The t value for Life Expectancy of 76:  1.1814424817202844 \n",
      "\n",
      "The p value for Life Expectancy of 76:  0.24423470312189977 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt_value_seventy, pp_value_seventy = ttest_1samp(europe_df['life_exp'], 70)\n",
    "print(\"The t value for Life Expectancy of 70: \", tt_value_seventy, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 70: \", pp_value_seventy, \"\\n\")\n",
    "\n",
    "tt_value_seventy_six, pp_value_seventy_six = ttest_1samp(europe_df['life_exp'], 76)\n",
    "print(\"The t value for Life Expectancy of 76: \", tt_value_seventy_six, \"\\n\")\n",
    "print(\"The p value for Life Expectancy of 76: \", pp_value_seventy_six, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Two </font>\n",
    "- https://www.geeksforgeeks.org/ways-to-filter-pandas-dataframe-by-column-values/\n",
    "- https://sparkbyexamples.com/pandas/pandas-filter-rows-by-conditions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = '#FF8C00'> Section 2 | Two Sample T-test </font>\n",
    "A two-sample t-test is meant to compare a numerical variable against a categorical variable. The goal is to assess whether the numerical variable is \"different\" across the categories. In this section, we compare the life expectancy in Europe against the life expectancy in Asia. We achieve this in the following steps below:\n",
    "- [x] Create a third data set that includes only rows in which regionname is “Asia.”\n",
    "- [x] The test statistic is shown in the formula section below. The p-values are also computed using the degrees of freedom, which is calculated using the formula below. \n",
    "- [x] Write a function that takes two data set inputs and returns the test statistic and p-values as outputs\n",
    "- [ ] We then use the function we built to assess whether the life expetancy in Europe is different than the life expectancy in Asia\n",
    "- [ ] We then validate the function by comparing the results to the built-in two sample t-test using the the `ttest_ind` method from `scipy.stats`.\n",
    "\n",
    "\n",
    "### <font color = '#FF8C00'> Formulas </font>\n",
    "$$\n",
    "t = \\frac{\\mu_1 - \\mu_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nu = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}\n",
    "{\\frac{s_1^4}{n_1^2 (n_1 - 1)} + \\frac{s_2^4}{n_2^2 (n_2 - 1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Filtering Out Asia </font>\n",
    "We start off by using the `new_world_df` data frame to filter out rows of data whose `regionname` is Asia. We would like to collect all the features and the data they have for each corresponding row to perform the two sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>life_exp</th>\n",
       "      <th>infant_mortality</th>\n",
       "      <th>phys_density</th>\n",
       "      <th>hospital_bed</th>\n",
       "      <th>health_exp_percent_gdp</th>\n",
       "      <th>OOP_percent_exp</th>\n",
       "      <th>health_exp_PC</th>\n",
       "      <th>fertility_rate</th>\n",
       "      <th>GNI_PC</th>\n",
       "      <th>regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>78.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87.6</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>86.4</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6260.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>34310.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>88.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  life_exp  infant_mortality  phys_density  hospital_bed  \\\n",
       "0   Afghanistan        42               165           2.0           4.0   \n",
       "7       Armenia        69                22          37.0          44.0   \n",
       "10   Azerbaijan        68                34          36.0          80.0   \n",
       "12      Bahrain        75                 9          27.0          27.0   \n",
       "13   Bangladesh        64                47           3.0           3.0   \n",
       "\n",
       "    health_exp_percent_gdp  OOP_percent_exp  health_exp_PC  fertility_rate  \\\n",
       "0                      9.2             78.5           91.0             7.1   \n",
       "7                      4.7             87.6          226.0             1.4   \n",
       "10                     4.1             86.4          254.0             1.8   \n",
       "12                     3.6             68.0            NaN             2.3   \n",
       "13                     3.2             88.3           37.0             2.9   \n",
       "\n",
       "     GNI_PC regionname  \n",
       "0       NaN       Asia  \n",
       "7    5900.0       Asia  \n",
       "10   6260.0       Asia  \n",
       "12  34310.0       Asia  \n",
       "13   1340.0       Asia  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering out the rows that have the regionname set as Asia\n",
    "asia_df = new_who_df[new_who_df['regionname'] == \"Asia\"]\n",
    "\n",
    "# displaying the data frame with just the top 5\n",
    "asia_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Building the Function </font>\n",
    "We build this function so that it takes two data sets as inputs and returns the test statistic and p-value as outputs. We implement the formulas mentioned above to help calculate the degrees of freedom, the test statistic and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function for the two sample t-test\n",
    "def two_sample_t_test(feature_col_one, feature_col_two):\n",
    "\n",
    "    # converting the feature into a list\n",
    "    feature_list_one = feature_col_one.tolist()\n",
    "    feature_list_two = feature_col_two.tolist()\n",
    "\n",
    "    # calculating the mean from the two features\n",
    "    mean_one = sum(feature_list_one) / len(feature_list_one)\n",
    "    mean_two = sum(feature_list_two) / len(feature_list_two)\n",
    "\n",
    "    # number of observations in each feature\n",
    "    observation_one = len(feature_list_one)\n",
    "    observation_two = len(feature_list_two)\n",
    "\n",
    "    # (observation - mean) ^ 2 for dataset one\n",
    "    difference_list_one = []\n",
    "    for row_one in range(0, len(feature_list_one)):\n",
    "        difference_one = (feature_list_one[row_one] - mean_one)**2\n",
    "        difference_list_one.append(difference_one)\n",
    "    \n",
    "    # (observation - mean) ^ 2 for dataset two\n",
    "    difference_list_two = []\n",
    "    for row_two in range(0, len(feature_list_two)):\n",
    "        difference_two = (feature_list_two[row_two] - mean_two)**2\n",
    "        difference_list_two.append(difference_two)\n",
    "    \n",
    "    # finding the sum of the different list one and two\n",
    "    sum_one = sum(difference_list_one)\n",
    "    sum_two = sum(difference_list_two)\n",
    "\n",
    "    # calculating the variance one and two\n",
    "    variance_one = sum_one / (observation_one - 1)\n",
    "    variance_two = sum_two / (observation_two - 1)\n",
    "\n",
    "    # calculating the standard deviation one and two\n",
    "    standard_deviation_one = math.sqrt(variance_one)\n",
    "    standard_deviation_two = math.sqrt(variance_two)\n",
    "\n",
    "    # calculating the numerator of the degrees of freedom\n",
    "    numerator = ((standard_deviation_one**2 / observation_one) + (standard_deviation_two**2 / observation_two))**2\n",
    "\n",
    "    # calculating the denominator part one\n",
    "    denominator_part_one = (standard_deviation_one**4) / ((observation_one**2) * (observation_one - 1))\n",
    "    denominator_part_two = (standard_deviation_two**4) / ((observation_two**2) * (observation_two - 1))\n",
    "    denominator = denominator_part_one + denominator_part_two\n",
    "\n",
    "    # calculating the degree of freedom\n",
    "    degree_of_freedom = numerator / denominator\n",
    "\n",
    "    # calculating the test statistic\n",
    "    t_value = (mean_one - mean_two) / math.sqrt((standard_deviation_one**2 / observation_one) + \n",
    "                                                (standard_deviation_two**2 / observation_two))\n",
    "    \n",
    "    # calculating the p value\n",
    "    p_value = 2 * (1 - t.cdf(abs(t_value), degree_of_freedom))\n",
    "\n",
    "    # returning the t_value and p_value\n",
    "    return t_value, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Life Expectancy in Europe vs Asia </font>\n",
    "We now calculate and compare the life expectancy in Europe vs in Asia. We do this by accessing the `life_exp` feature from both the data frames of Asia `asia_df` and Europe `europe_df`. We then take these features and put it into the function and get the t_value and p_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test statistic value of Life Expectancy in Europe vs Asia:  -5.884174172667128 \n",
      "\n",
      "The p value of Life Expectancy of Europe vs Asia:  9.527883593207775e-08\n"
     ]
    }
   ],
   "source": [
    "# using the function to retrieve the t_value and p_value\n",
    "t_value, p_value = two_sample_t_test(asia_df[\"life_exp\"], europe_df[\"life_exp\"])\n",
    "print(\"The test statistic value of Life Expectancy in Europe vs Asia: \", t_value, \"\\n\")\n",
    "print(\"The p value of Life Expectancy of Europe vs Asia: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = '#FF8C00'> Validating the Function </font>\n",
    "We now work on validating the function. We achieve this by using the `ttest_ind` method from the `scipy.stats` library. We then use the values we get from the method, to compare against the function we created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Statistics of Life Expectancy in Europe vs Asia:  -5.884174172667128 \n",
      "\n",
      "The p Value of Life Expectancy in Europe vs Asia:  1.0064936415173571e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing the scipy.stats library\n",
    "from scipy import stats\n",
    "\n",
    "# running the ttest_ind method from the scipy.stats library\n",
    "t_value, p_value = stats.ttest_ind(a=asia_df[\"life_exp\"], b=europe_df[\"life_exp\"], equal_var=False)\n",
    "\n",
    "# printing out the test statistic and p value\n",
    "print(\"The Test Statistics of Life Expectancy in Europe vs Asia: \", t_value, \"\\n\")\n",
    "print(\"The p Value of Life Expectancy in Europe vs Asia: \", p_value, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#FF8C00'> Sources Used For Section Three </font>\n",
    "- https://www.geeksforgeeks.org/how-to-conduct-a-two-sample-t-test-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScienceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
